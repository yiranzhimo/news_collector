from flask import Flask, request
import os
import requests
from bs4 import BeautifulSoup
import chardet  # âœ… æ–°å¢ï¼šè‡ªåŠ¨æ£€æµ‹ç½‘é¡µç¼–ç 

app = Flask(__name__)

# ä» Vercel ç¯å¢ƒå˜é‡è¯»å–
BOT_TOKEN = os.environ.get("BOT_TOKEN")
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
REPO = os.environ.get("REPO")

print("ğŸ”¹ Debug Info:")
print("BOT_TOKEN:", BOT_TOKEN)
print("REPO:", REPO)

def fetch_page_info(link):
    """å¯é çš„ç½‘é¡µæŠ“å–å‡½æ•°ï¼Œé˜²ä¹±ç ï¼ˆè‡ªåŠ¨æ£€æµ‹ç¼–ç ï¼‰"""
    try:
        res = requests.get(link, timeout=10)
        raw_data = res.content

        # ä¼˜å…ˆä»é¡µé¢å†…å®¹è‡ªåŠ¨è¯†åˆ«ç¼–ç æ„å»º soupï¼Œæ”¯æŒæ—  lxml ç¯å¢ƒ
        soup = None
        for parser in ("lxml", "html.parser"):
            try:
                soup = BeautifulSoup(raw_data, parser)
                break
            except Exception:
                continue
        if soup is None:
            raise RuntimeError("No HTML parser available")

        # è‹¥æ ‡é¢˜ç¼ºå¤±ï¼Œå†å›é€€æŒ‰å¤šç¼–ç è§£ç åé‡å»º soup
        if soup.title and soup.title.string:
            title = soup.title.string.strip()
        else:
            detected = chardet.detect(raw_data)
            enc_candidates = [
                res.encoding,
                detected.get("encoding"),
                getattr(res, "apparent_encoding", None),
                "utf-8",
                "gb18030",
            ]
            seen = set()
            text = None
            for enc in [e for e in enc_candidates if e and not (e in seen or seen.add(e))]:
                try:
                    text = raw_data.decode(enc)
                    break
                except Exception:
                    continue
            text = text or raw_data.decode("utf-8", errors="ignore")

            for parser in ("lxml", "html.parser"):
                try:
                    soup = BeautifulSoup(text, parser)
                    break
                except Exception:
                    continue
            title = soup.title.string.strip() if soup and soup.title else "No Title"

        paragraphs = " ".join(p.get_text() for p in soup.find_all("p")) if soup else ""
        summary = paragraphs[:200] + "..." if len(paragraphs) > 200 else paragraphs

        return title, summary

    except Exception as e:
        return "No Title", f"Failed to fetch: {e}"

@app.route(f"/{BOT_TOKEN}", methods=["POST"])
def webhook():
    data = request.get_json()
    print("ğŸ”¹ Received data:", data)

    message = data.get("message", {})
    text = message.get("text", "")

    if text.startswith("http"):
        link = text
        title, summary = fetch_page_info(link)

        # åˆ›å»º GitHub Issue
        url = f"https://api.github.com/repos/{REPO}/issues"
        headers = {"Authorization": f"token {GITHUB_TOKEN}"}
        data_issue = {"title": title, "body": f"{summary}\n\n[é˜…è¯»åŸæ–‡]({link})"}
        r = requests.post(url, json=data_issue, headers=headers)

        if r.status_code == 201:
            print("âœ… Issue created:", title)
        else:
            print("âŒ Failed to create issue:", r.text)

        # å›å¤ Telegram
        chat_id = message["chat"]["id"]
        reply = f"ğŸ“° å·²ä¿å­˜åˆ° GitHubï¼š{title}" if r.status_code == 201 else f"âŒ åˆ›å»ºå¤±è´¥ï¼š{r.text}"
        requests.get(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            params={"chat_id": chat_id, "text": reply}
        )

    return "ok"

@app.route("/")
def index():
    return "Telegram News Bot is running âœ…"

if __name__ == "__main__":
    app.run()
